{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "End-To-End-v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMYI9YDTk3OR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0dc9b4-4f6f-4890-ddf1-cb41e68aa1ea"
      },
      "source": [
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4No0K4CkkD0j"
      },
      "source": [
        "# Configuration Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZySbnsSj06o"
      },
      "source": [
        "#INPUTS For Selective Search and Edge Boxes\n",
        "image_path = '/content/Rice_Img1.jpeg'\n",
        "method = 'fast' #or quality\n",
        "percentage = 0.1\n",
        "image_dims  = (416,416) \n",
        "proposal_dims = (224,224)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6nis4LKjFgg"
      },
      "source": [
        "#INPUT Food Dictionary For Post-processing And Giving Final Labels, Servings and Calories.\n",
        "food_dic = {\n",
        "    \"Apple_Pie\":\n",
        "    \n",
        "    {\n",
        "    \"class_id\": 0,\n",
        "    \"food_name\": \"Apple Pie\",\n",
        "    \"fatsecret_food_id\": \"4057\",\n",
        "    \"food_description\": \"Per 1164g - Calories: 4364kcal | Fat: 259.17g | Carbs: 482.49g | Protein: 36.19g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\": \"area\",\n",
        "    \"serving_size\": 1164,\n",
        "    \"calories_kcal\": 4364,\n",
        "    \"fat\": 259.17,\n",
        "    \"carbs\":  482.49,\n",
        "    \"protein\": 36.19,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/pie-apple-fried-pie\",\n",
        "    \"area_overlap_constant\": 0.85\n",
        "  },\n",
        "  \"Bagel_With_Cream_Cheese\":\n",
        "\n",
        "  {\n",
        "    \"class_id\": 1,\n",
        "    \"food_name\": \"Bagel with Cream Cheese\",\n",
        "    \"fatsecret_food_id\": \"11876565\",\n",
        "    \"food_description\": \"Per 120g or Per 1 bagel - Calories: 327kcal | Fat: 8.59g | Carbs: 51.03g | Protein: 11.53g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"count\",\n",
        "    \"serving_size\": 1,\n",
        "    \"calories_kcal\": 327,\n",
        "    \"fat\": 8.59,\n",
        "    \"carbs\":  51.03,\n",
        "    \"protein\": 11.53,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/bagel-with-cream-cheese\"\n",
        "  },\n",
        "\n",
        "    \"Banana\":\n",
        "  {\n",
        "    \"class_id\": 2,\n",
        "    \"food_name\": \"Banana\",\n",
        "    \"fatsecret_food_id\": \"5388\",\n",
        "    \"food_description\": \"Per 1 medium Banana or Per 100g - Calories: 89kcal | Fat: 0.33g | Carbs: 22.84g | Protein: 1.09g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"count\",\n",
        "    \"serving_size\": 1,\n",
        "    \"calories_kcal\": 89,\n",
        "    \"fat\": 0.33,\n",
        "    \"carbs\":  22.84,\n",
        "    \"protein\": 1.09,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/banana-raw\"\n",
        "  },\n",
        "  \"Blackberries\":\n",
        "  {\n",
        "    \"class_id\": 3,\n",
        "    \"food_name\": \"Blackberries\",\n",
        "    \"fatsecret_food_id\": \"35757\",\n",
        "    \"food_description\": \"Per 740g - Calories: 318.2kcal | Fat: 3.626g | Carbs: 71.114g | Protein: 10.286g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"area\",\n",
        "    \"serving_size\": 740,\n",
        "    \"calories_kcal\": 318.2,\n",
        "    \"fat\": 3.626,\n",
        "    \"carbs\":  71.114,\n",
        "    \"protein\": 10.286,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/usda/blackberries\"\n",
        "  },\n",
        "\n",
        "    \"Black_Grapes\":\n",
        "  {\n",
        "    \"class_id\": 4,\n",
        "    \"food_name\": \"Black Grapes\",\n",
        "    \"fatsecret_food_id\": \"5422\",\n",
        "    \"food_description\": \"Per 437g - Calories: 301.53kcal | Fat: 69.92g | Carbs: 79.097g | Protein: 3.14g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"count\",\n",
        "    \"serving_size\": 437,\n",
        "    \"calories_kcal\": 301.53,\n",
        "    \"fat\": 69.92,\n",
        "    \"carbs\":  79.097,\n",
        "    \"protein\": 3.14,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/grapes-raw\"\n",
        "  },\n",
        "    \"Chicken_Breast\":\n",
        "  {\n",
        "    \"class_id\": 5,\n",
        "    \"food_name\": \"Chicken Breast\",\n",
        "    \"fatsecret_food_id\": \"1641\",\n",
        "    \"food_description\": \"Per 1009g - Calories: 1968.04kcal | Fat: 77.8g | Carbs: 0.00g | Protein: 297.70g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"area\",\n",
        "    \"serving_size\": 1009,\n",
        "    \"calories_kcal\": 1968.04,\n",
        "    \"fat\": 77.8,\n",
        "    \"carbs\":  0.00,\n",
        "    \"protein\": 297.70,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/chicken-breast-ns-as-to-skin-eaten\"\n",
        "  },\n",
        "    \"Chicken_Burrito_Bowl\":\n",
        "  {\n",
        "    \"class_id\": 6,\n",
        "    \"food_name\": \"Chicken Burrito Bowl\",\n",
        "    \"fatsecret_food_id\": \"14920855\",\n",
        "    \"food_description\": \"Per 1 bowl or Per 328.85 gm or 11.6 ounce - Calories: 370kcal | Fat: 10.00g | Carbs: 51.00g | Protein: 22.00g\",\n",
        "    \"food_type\": \"Brand\",\n",
        "    \"brand_name\": \"Trader Joe's\",\n",
        "    \"calorie_measure\":\"area\",\n",
        "    \"serving_size\": 328.85,\n",
        "    \"calories_kcal\": 370,\n",
        "    \"fat\": 10.00,\n",
        "    \"carbs\":  51.00,\n",
        "    \"protein\": 22.00,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/trader-joes/chicken-burrito-bowl\"\n",
        "  },\n",
        "    \"Cookie\":\n",
        "  {\n",
        "    \"class_id\": 7,\n",
        "    \"food_name\": \"Cookie\",\n",
        "    \"fatsecret_food_id\": \"3936\",\n",
        "    \"food_description\": \"1 cookies - Calories: 121.5kcal | Fat: 5.34g | Carbs: 17.24g | Protein: 1.355g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"count\",\n",
        "    \"serving_size\": 1,\n",
        "    \"calories_kcal\": 121.5,\n",
        "    \"fat\": 5.34,\n",
        "    \"carbs\":  17.24,\n",
        "    \"protein\": 1.355,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/cookie\"\n",
        "  },\n",
        "  \"Energy_Bars\":\n",
        "  {\n",
        "    \"class_id\": 8,\n",
        "    \"food_name\": \"Energy Bars\",\n",
        "    \"fatsecret_food_id\": \"21653857\",\n",
        "    \"food_description\": \"Per 1 bar - Calories: 220kcal | Fat: 3.00g | Carbs: 40.00g | Protein: 9.00g\",\n",
        "    \"food_type\": \"Brand\",\n",
        "    \"calorie_measure\":\"count\",\n",
        "    \"serving_size\": 1,\n",
        "    \"calories_kcal\": 220,\n",
        "    \"fat\": 3,\n",
        "    \"carbs\":  40,\n",
        "    \"protein\": 9,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/xs/energy-bars-blueberry-crunch\"\n",
        "  },\n",
        "  \"French_Fries\":\n",
        "  {\n",
        "    \"class_id\": 9,\n",
        "    \"food_name\": \"French Fries\",\n",
        "    \"fatsecret_food_id\": \"5762\",\n",
        "    \"food_description\": \"Per 270g - Calories: 739.8kcal | Fat: 38.016g | Carbs: 96.417g | Protein: 9.423g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"area\",\n",
        "    \"serving_size\": 270,\n",
        "    \"calories_kcal\": 739.8,\n",
        "    \"fat\": 38.01,\n",
        "    \"carbs\":  96.417,\n",
        "    \"protein\": 9.423,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/white-potato-french-fries\"\n",
        "  },\n",
        "\n",
        "  \"Fruit_Flavored_Yogurts\":\n",
        "  { \n",
        "    \"class_id\": 10,\n",
        "    \"food_name\": \"Fruit Flavoured Yogurt\",\n",
        "    \"fatsecret_food_id\": \"859\",\n",
        "    \"food_description\": \"Per 1166g - Calories: 1189.32kcal | Fat: 12.59g | Carbs: 222.123g | Protein: 50.95g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"area\",\n",
        "    \"serving_size\": 1166,\n",
        "    \"calories_kcal\": 1189.32,\n",
        "    \"fat\": 12.59,\n",
        "    \"carbs\":  222.123,\n",
        "    \"protein\": 50.95,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/yogurt-fruit-variety-lowfat-milk\"\n",
        "  },\n",
        "\n",
        "    \"Pasta\":\n",
        "  {\n",
        "    \"class_id\": 11,\n",
        "    \"food_name\": \"Pasta\",\n",
        "    \"fatsecret_food_id\": \"285243\",\n",
        "    \"food_description\": \"Per 583.32g - Calories: 912kcal | Fat: 5.36g | Carbs: 178.13g | Protein: 33.47g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"area\",\n",
        "    \"serving_size\": 583.32,\n",
        "    \"calories_kcal\": 912,\n",
        "    \"fat\": 5.36,\n",
        "    \"carbs\":  178.13,\n",
        "    \"protein\": 33.47,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/penne-cooked\"\n",
        "  },\n",
        "    \"Toasted_Bagel_With_Butter\":\n",
        "  {\n",
        "    \"class_id\": 12,\n",
        "    \"food_name\": \"Toasted Bagel With Butter\",\n",
        "    \"fatsecret_food_id\": \"3541\",\n",
        "    \"food_description\": \"Per 1 Bagel or Per 100g - Calories: 288kcal | Fat: 1.72g | Carbs: 57.11g | Protein: 11.14g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"count\",\n",
        "    \"serving_size\": 1,\n",
        "    \"calories_kcal\": 288,\n",
        "    \"fat\": 1.72,\n",
        "    \"carbs\":  57.11,\n",
        "    \"protein\": 11.14,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/bagel-toasted\"\n",
        "  },\n",
        "    \"Toasted_Bread\":\n",
        "  {\n",
        "    \"class_id\": 13,\n",
        "    \"food_name\": \"Toasted Bread\",\n",
        "    \"fatsecret_food_id\": \"2816154\",\n",
        "    \"food_description\": \"Per 1 slice - Calories: 70kcal | Fat: 1.50g | Carbs: 11.00g | Protein: 2.00g\",\n",
        "    \"food_type\": \"Brand\",\n",
        "    \"calorie_measure\":\"count\",\n",
        "    \"serving_size\": 1,\n",
        "    \"calories_kcal\": 70,\n",
        "    \"fat\": 1.50,\n",
        "    \"carbs\":  11.00,\n",
        "    \"protein\": 2,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/bimbo/toasted-bread-original\"\n",
        "  },\n",
        "    \"White_Rice\":\n",
        "  {\n",
        "    \"class_id\": 14,\n",
        "    \"food_name\": \"White Rice\",\n",
        "    \"fatsecret_food_id\": \"4501\",\n",
        "    \"food_description\": \"Per 875g - Calories: 1126.5kcal | Fat: 2.46g | Carbs: 243.35g | Protein: 23.18g\",\n",
        "    \"food_type\": \"Generic\",\n",
        "    \"calorie_measure\":\"area\",\n",
        "    \"serving_size\": 875,\n",
        "    \"calories_kcal\": 1126.5,\n",
        "    \"fat\": 2.46,\n",
        "    \"carbs\":  243.35,\n",
        "    \"protein\": 23.18,\n",
        "    \"fatsecret_food_url\": \"https://www.fatsecret.com/calories-nutrition/generic/rice-white-cooked-regular\"\n",
        "  }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BtAflvH2Cu2"
      },
      "source": [
        "# target_cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBGl5PCKj2zq"
      },
      "source": [
        "#INPUTS for classifier - Food\n",
        "# ====================================================\n",
        "# Directory settings\n",
        "# ====================================================\n",
        "import os\n",
        "\n",
        "model_path = '/content/drive/MyDrive/multilabel_retrain/models/resnext50_32x4d_fold2_best.pth'\n",
        "# MODEL_DIR = '/content/drive/MyDrive/multilabel_retrain/models/'\n",
        "OUTPUT_DIR = './'\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "TEST_PATH = r'/content/drive/MyDrive/intellihealth_test_data/'\n",
        "# train = pd.read_csv('/content/drive/MyDrive/multilabel_retrain/train_folds.csv')\n",
        "# test = pd.read_csv(r'/content/drive/MyDrive/multilabel_retrain/test.csv')\n",
        "# print(test.shape)\n",
        "# test.tail()\n",
        "\n",
        "# ====================================================\n",
        "# CFG\n",
        "# ====================================================\n",
        "class CFG:\n",
        "    debug=False\n",
        "    num_workers=4\n",
        "    model_name='resnext50_32x4d'\n",
        "    size=224\n",
        "    batch_size=128\n",
        "    seed=42\n",
        "    target_size=15\n",
        "    target_cols=[\n",
        "                 \"Apple_Pie\",\"Bagel_With_Cream_Cheese\",\"Banana\",\"Blackberries\",\"Black_Grapes\",\"Chicken_Breast\",\n",
        "                 \"Chicken_Burrito_Bowl\",\"Cookie\",\"Energy_Bars\",\"French_Fries\",\"Fruit_Flavored_Yogurts\",\"Pasta\",\n",
        "                 \"Toasted_Bagel_With_Butter\",\"Toasted_Bread\",\"White_Rice\"\n",
        "                 ]\n",
        "    n_fold=1\n",
        "    trn_fold=[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Cci7vUcpsy"
      },
      "source": [
        "#INPUTS for classifier - Plate\n",
        "# ====================================================\n",
        "# Directory settings\n",
        "# ====================================================\n",
        "import os\n",
        "\n",
        "Plate_OUTPUT_DIR = './'\n",
        "Plate_MODEL_DIR = '/content/drive/MyDrive/classification_plate/models/'\n",
        "if not os.path.exists(Plate_OUTPUT_DIR):\n",
        "    os.makedirs(Plate_OUTPUT_DIR)\n",
        "\n",
        "TEST_PATH = '/content/drive/MyDrive/intellihealth_test_data/'\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# CFG\n",
        "# ====================================================\n",
        "class Plate_CFG:\n",
        "    debug=False\n",
        "    num_workers=4\n",
        "    model_name='resnext50_32x4d'\n",
        "    size=256\n",
        "    batch_size=32\n",
        "    seed=42\n",
        "    target_size=5\n",
        "    target_col='Plate'\n",
        "    n_fold=5\n",
        "    # n_fold=1\n",
        "    trn_fold=[0, 1, 2, 3, 4]\n",
        "    # trn_fold=[2]\n",
        "    train=False\n",
        "    inference=True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nssfIGBSdCPb"
      },
      "source": [
        "#INPUTS for Generating Final Food Labels - Plate\n",
        "\n",
        "#Inputs:\n",
        "Plate_target_cols =['Plate']\n",
        "                 \n",
        "# classifier_output = None # The Dataframe output of the classification model\n",
        "Plate_classifier_confidence_thresh = 90\n",
        "Plate_nms_thresh = 0.1\n",
        "# image_path = '/content/Rice_Img1.jpeg'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "galQn5n9j4J1"
      },
      "source": [
        "#INPUTS for Generating Final Food Labels - Food\n",
        "\n",
        "#Inputs:\n",
        "target_cols=[\n",
        "                 \"Apple_Pie\",\"Bagel_With_Cream_Cheese\",\"Banana\",\"Blackberries\",\"Black_Grapes\",\"Chicken_Breast\",\n",
        "                 \"Chicken_Burrito_Bowl\",\"Cookie\",\"Energy_Bars\",\"French_Fries\",\"Fruit_Flavored_Yogurts\",\"Pasta\",\n",
        "                 \"Toasted_Bagel_With_Butter\",\"Toasted_Bread\",\"White_Rice\"\n",
        "                 ]\n",
        "# classifier_output = None # The Dataframe output of the classification model\n",
        "classifier_confidence_thresh = 90\n",
        "nms_thresh = 0.1\n",
        "# image_path = '/content/Rice_Img1.jpeg'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqa8zk9gXMsM"
      },
      "source": [
        "#Empty Food Dataframe For The Main Function To Deal With Empty Proposals Array Case.\n",
        "edf = pd.DataFrame()\n",
        "for i in target_cols:\n",
        "  edf[i] = [0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvWjUCD-_7k-"
      },
      "source": [
        "# Selective Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsuknZP4AM9H"
      },
      "source": [
        "#Function For Generating Object Proposals\n",
        "import imutils\n",
        "from time import perf_counter\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def selective_search(image, method=\"fast\"):\n",
        "\tss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
        "\tss.setBaseImage(image)\n",
        "\tif method == \"fast\":\n",
        "\t\tss.switchToSelectiveSearchFast()\n",
        "\telse:\n",
        "\t\tss.switchToSelectiveSearchQuality()\n",
        "\trects = ss.process()\n",
        "\treturn rects\n",
        "\n",
        "def selective_search_cv(image_path, method='fast',percentage=0.1, image_dims=(416,416), proposal_dims = (224,224)):\n",
        "  '''Generates class-agnostic object proposals for a given image.\n",
        "\n",
        "  Takes the image path, resizes it, passes it through OpenCV's selective search function, eliminates boxes based on size,\n",
        "  and finally returns the image proposal arrays and their respective box coordinates.\n",
        "\n",
        "  Files Required:\n",
        "    None.\n",
        "\n",
        "  Args:\n",
        "    image_path:\n",
        "      A string.\n",
        "      Absolute path to the image. \n",
        "    method:\n",
        "      A string.\n",
        "      Method to use, 'fast' or 'quality', while calling OpenCV's selective search function. \n",
        "      (default is 'fast')\n",
        "    percentage:\n",
        "      A float. \n",
        "      The percentage of the image width, height to be used as a threshold while eliminating proposals based on size.\n",
        "      Example - if value = 0.1, all proposals whose width/height is less than 10% of the image width of height will \n",
        "      be eliminated. (default is 0.1 i.e. 10%)\n",
        "    image_dims:\n",
        "      A tuple.\n",
        "      The dimensions to which the the image must be resized before passing it through the selective search function.\n",
        "      For convenience, must be same as the value used during object detection (ex - YOLO), if object detection is used\n",
        "      in other stages. \n",
        "      (default is (416,416))\n",
        "    proposal_dims:\n",
        "      A tuple.\n",
        "      The dimensions to which the proposals generated will be resized to.\n",
        "      Must be same as the input resolution of the classification model used in further stages. \n",
        "      (default is (224,224))\n",
        "\n",
        "  Returns:\n",
        "    proposals:\n",
        "      A numpy.ndarray of shape (no. of proposals, proposal_dims, 3). Example - (687, 224, 224, 3)\n",
        "      The image proposal arrays after selective search and size based elimination. \n",
        "    boxes:\n",
        "      A list of shape (no. of proposals, 4).\n",
        "      List containing the box coordinates for the respective proposals.\n",
        "      Coordinates format = (x, y, width, height). Here x,y are the coordinates of the top left corner of the box.\n",
        "  '''\n",
        "\n",
        "  #Resize Image\n",
        "  (width,height)  = image_dims\n",
        "  image = cv2.imread(image_path)\n",
        "  (H,W) = image.shape[:2]\n",
        "  if W>H:\n",
        "    image = imutils.resize(image, width=width)\n",
        "  else: \n",
        "    image = imutils.resize(image, height=height)\n",
        "  # print(image.shape)\n",
        "  #Generate Proposals\n",
        "  t1_start = perf_counter() \n",
        "  rects = selective_search(image, method)\n",
        "  t1_stop = perf_counter()\n",
        "  print(\"[INFO] selective search took {:.4f} seconds\".format(t1_stop - t1_start))\n",
        "  print(\"[INFO] {} regions found by selective search\".format(len(rects)))\n",
        "  proposals = []\n",
        "  boxes = []\n",
        "  #Eliminate boxes based on size.\n",
        "  for (x, y, w, h) in rects:\n",
        "    if w / float(W) < percentage or h / float(H) < percentage:\n",
        "      continue\n",
        "    roi = image[y:y + h, x:x + w]\n",
        "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB) #CV\n",
        "    roi = cv2.resize(roi, proposal_dims) #CV\n",
        "    roi = img_to_array(roi)\n",
        "    # roi = preprocess_input(roi) #For Keras Resnet Model\n",
        "    proposals.append(roi) #list\n",
        "    boxes.append((x, y, w, h))\n",
        "  proposals = np.asarray(proposals, dtype= np.uint8) \n",
        "  print('[INFO] Proposals Shape After Size Based Elimination:',proposals.shape)\n",
        "  print('[INFO] Boxes Shape After Size Based Elimination:',np.shape(boxes))\n",
        "  return proposals, boxes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWtvETsAeeNR"
      },
      "source": [
        "# #Sample Function Call - Input And Requirements\n",
        "\n",
        "# image_path = '/content/pasta2.jpg'\n",
        "# method = 'fast'\n",
        "# percentage = 0.1\n",
        "# image_dims = (416,416)\n",
        "# proposal_dims = (224,224)\n",
        "\n",
        "# proposals, boxes = selective_search_cv(image_path, method,percentage, image_dims, proposal_dims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIVj3Yt9-DEz"
      },
      "source": [
        "#Edge Boxes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLbA4jpe-F4j"
      },
      "source": [
        "import cv2 as cv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "def image_resize(img, size=(28,28)):\n",
        "    h, w = img.shape[:2]\n",
        "    c = img.shape[2] if len(img.shape)>2 else 1\n",
        "\n",
        "    if h == w: \n",
        "        return cv2.resize(img, size, cv2.INTER_AREA)\n",
        "\n",
        "    dif = h if h > w else w\n",
        "\n",
        "    interpolation = cv2.INTER_AREA if dif > (size[0]+size[1])//2 else cv2.INTER_CUBIC\n",
        "\n",
        "    x_pos = (dif - w)//2\n",
        "    y_pos = (dif - h)//2\n",
        "    if len(img.shape) == 2:\n",
        "        mask = np.zeros((dif, dif), dtype=img.dtype)\n",
        "        mask[y_pos:y_pos+h, x_pos:x_pos+w] = img[:h, :w]\n",
        "    else:\n",
        "        mask = np.zeros((dif, dif, c), dtype=img.dtype)\n",
        "        mask[y_pos:y_pos+h, x_pos:x_pos+w, :] = img[:h, :w, :]\n",
        "\n",
        "    return cv2.resize(mask, size, interpolation)\n",
        "\n",
        "\n",
        "def get_proposals(img_path, image_dims, proposal_dims, max_boxes = 100, percentage=0.1, eb_model_path = '/content/drive/MyDrive/EdgeBoxes/EB_model.yml'):\n",
        "  '''Generates class-agnostic object proposals for a given image.\n",
        "\n",
        "  Takes the image path, resizes it, passes it through OpenCV's edge boxes function, eliminates boxes based on size,\n",
        "  and finally returns the image proposal arrays and their respective box coordinates.\n",
        "\n",
        "  Files Required:\n",
        "    The yml file required to run the edge boxes algorithm.\n",
        "\n",
        "  Args:\n",
        "    image_path:\n",
        "      A string.\n",
        "      Absolute path to the image. \n",
        "    image_dims:\n",
        "      A tuple.\n",
        "      The dimensions to which the the image must be resized before passing it through the selective search function.\n",
        "      For convenience, must be same as the value used during object detection (ex - YOLO), if object detection is used\n",
        "      in other stages. \n",
        "      (default is (416,416))\n",
        "    proposal_dims:\n",
        "      A tuple.\n",
        "      The dimensions to which the proposals generated will be resized to.\n",
        "      Must be same as the input resolution of the classification model used in further stages. \n",
        "      (default is (224,224))\n",
        "    max_boxes:\n",
        "      An int.\n",
        "      The maximum number of boxes that Edge Boxes Will generate.\n",
        "      (default is 100)\n",
        "    percentage:\n",
        "      A float. \n",
        "      The percentage of the image width, height to be used as a threshold while eliminating proposals based on size.\n",
        "      Example - if value = 0.1, all proposals whose width/height is less than 10% of the image width of height will \n",
        "      be eliminated. (default is 0.1 i.e. 10%)\n",
        "    eb_model_path:\n",
        "      A string.\n",
        "      Absolute path to the .yml file needed to run the Edge Boxes algorithm.\n",
        "\n",
        "\n",
        "  Returns:\n",
        "    proposals:\n",
        "      A numpy.ndarray of shape (no. of proposals, proposal_dims, 3). Example - (687, 224, 224, 3)\n",
        "      The image proposal arrays after selective search and size based elimination. \n",
        "    boxes:\n",
        "      A list of shape (no. of proposals, 4).\n",
        "      List containing the box coordinates for the respective proposals.\n",
        "      Coordinates format = (x, y, width, height). Here x,y are the coordinates of the top left corner of the box.\n",
        "  '''\n",
        "  \n",
        "  image = cv.imread(img_path)\n",
        "\n",
        "  (width,height)  = image_dims\n",
        "  image = cv2.imread(image_path)\n",
        "  (H,W) = image.shape[:2]\n",
        "  if W>H:\n",
        "    image = imutils.resize(image, width=width)\n",
        "  else: \n",
        "    image = imutils.resize(image, height=height)\n",
        "\n",
        "  # image = image_resize(image, size=image_dims)\n",
        "  # cv.imwrite('resized.jpg', image)\n",
        "  # im = cv.imread('resized.jpg')\n",
        "  exit()\n",
        "  try:\n",
        "    edge_detection = cv.ximgproc.createStructuredEdgeDetection(eb_model_path)\n",
        "  except:\n",
        "    raise Exception(\"Check the parameter eb_model_path containing the path to the edge boxes model file.\")\n",
        "  rgb_im = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "  edges = edge_detection.detectEdges(np.float32(rgb_im) / 255.0)\n",
        "  orimap = edge_detection.computeOrientation(edges)\n",
        "  edges = edge_detection.edgesNms(edges, orimap)\n",
        "  start = time.perf_counter()\n",
        "  edge_boxes = cv.ximgproc.createEdgeBoxes()\n",
        "  edge_boxes.setMaxBoxes(max_boxes)\n",
        "  boxes = edge_boxes.getBoundingBoxes(edges, orimap)[0]\n",
        "  tot_time = time.perf_counter() - start \n",
        "  print(f\"[INFO] Edge boxes took {tot_time} seconds to generate {len(boxes)} region proposals.\")\n",
        "  proposals, rects, boxes = list(), list(boxes), list()\n",
        "  H, W = image.shape[:2]\n",
        "  for b in rects:\n",
        "      x, y, w, h = b\n",
        "      if w / float(W) > percentage or h / float(H) > percentage:\n",
        "        roi = image[y:y + h, x:x + w]\n",
        "        roi = cv.cvtColor(roi, cv.COLOR_BGR2RGB) #CV\n",
        "        roi = cv.resize(roi, proposal_dims) #CV\n",
        "        roi = img_to_array(roi)\n",
        "        proposals.append(roi)\n",
        "        boxes.append((x, y, w, h))\n",
        "  proposals = np.asarray(proposals, dtype= np.uint8) # For Array input method\n",
        "  print(\"[INFO] proposal shape: {}\".format(proposals.shape))\n",
        "  return proposals, boxes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjB9q4pl-WX9"
      },
      "source": [
        "# #Sample Function Call\n",
        "# #Requirements : Need The Model.yml\n",
        "# #Inputs:\n",
        "image_path = '/content/pasta2.jpg'\n",
        "image_dims = (416,416)\n",
        "proposal_dims = (224,224)\n",
        "max_boxes = 100\n",
        "percentage = 0.1\n",
        "eb_model_path = '/content/drive/MyDrive/EdgeBoxes/EB_model.yml'\n",
        "# props, boxes = get_proposals(image_path, image_dims, proposal_dims, max_boxes, percentage, eb_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z5s6AjYAX7J"
      },
      "source": [
        "# Classification - Food"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ja488ng9JMi"
      },
      "source": [
        "#INPUT CFG for classifier - Food\n",
        "# ====================================================\n",
        "# Directory settings\n",
        "# ====================================================\n",
        "import os\n",
        "\n",
        "model_path = '/content/drive/MyDrive/multilabel_retrain/models/resnext50_32x4d_fold2_best.pth'\n",
        "OUTPUT_DIR = './'\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "# ====================================================\n",
        "# CFG\n",
        "# ====================================================\n",
        "class CFG:\n",
        "    debug=False\n",
        "    num_workers=4\n",
        "    model_name='resnext50_32x4d'\n",
        "    size=224\n",
        "    batch_size=128\n",
        "    seed=42\n",
        "    target_size=15\n",
        "    target_cols=[\n",
        "                 \"Apple_Pie\",\"Bagel_With_Cream_Cheese\",\"Banana\",\"Blackberries\",\"Black_Grapes\",\"Chicken_Breast\",\n",
        "                 \"Chicken_Burrito_Bowl\",\"Cookie\",\"Energy_Bars\",\"French_Fries\",\"Fruit_Flavored_Yogurts\",\"Pasta\",\n",
        "                 \"Toasted_Bagel_With_Butter\",\"Toasted_Bread\",\"White_Rice\"\n",
        "                 ]\n",
        "    n_fold=1\n",
        "    trn_fold=[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCr4bvOdAaqF"
      },
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "! pip -q install albumentations==0.4.6\n",
        "! pip -q install timm\n",
        "! pip -q install kornia\n",
        "\n",
        "import kornia\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import kornia\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import sys\n",
        "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from contextlib import contextmanager\n",
        "from collections import defaultdict, Counter\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "from tqdm.auto import tqdm\n",
        "from functools import partial\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "import torchvision.models as models\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
        "from albumentations import (\n",
        "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
        "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
        "    IAAAdditiveGaussianNoise, Transpose\n",
        "    )\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from albumentations import ImageOnlyTransform\n",
        "import timm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# Get Path of all images in a folder\n",
        "# ====================================================\n",
        "def get_path(TEST_PATH):\n",
        "    image_names = os.listdir(TEST_PATH) #list of images\n",
        "    list_of_images = []\n",
        "    for f in image_names: #iterating over each image to get its name\n",
        "        image_path = os.path.join(TEST_PATH, f) #joining name with path of the parent directory to get the path of the image\n",
        "        list_of_images.append(image_path)\n",
        "    return list_of_images\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# Utils\n",
        "# ====================================================\n",
        "\n",
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f'[{name}] start')\n",
        "    yield\n",
        "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
        "\n",
        "\n",
        "def init_logger(log_file=OUTPUT_DIR+'inference.log'):\n",
        "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_torch(seed=CFG.seed)\n",
        "\n",
        "if CFG.debug:\n",
        "    test = test.head()\n",
        "\n",
        "# ====================================================\n",
        "# MODEL\n",
        "# ====================================================\n",
        "class CustomResNext(nn.Module):\n",
        "    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
        "        n_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "# ====================================================\n",
        "# Helper functions\n",
        "# ====================================================\n",
        "def inference(model, states, test_loader, device):\n",
        "    model.to(device)\n",
        "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
        "    probs = []\n",
        "    for i, (images) in tk0:\n",
        "        images = images.to(device)\n",
        "        avg_preds = []\n",
        "        for state in states:\n",
        "            model.load_state_dict(state['model'])\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                y_preds = model(images)\n",
        "            avg_preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
        "        avg_preds = np.mean(avg_preds, axis=0)\n",
        "        probs.append(avg_preds)\n",
        "    probs = np.concatenate(probs)\n",
        "    return probs\n",
        "\n",
        "def preprocess(proposals):\n",
        "    preprocessed_array = []\n",
        "    number, height, width, channels = proposals.shape\n",
        "    for i in range(number):\n",
        "        preprocess = transforms.Compose([\n",
        "                                         transforms.ToPILImage(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Scale(256),\n",
        "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                         ])\n",
        "        j = preprocess(proposals[i])\n",
        "        np_arr = j.cpu().detach().numpy()\n",
        "        preprocessed_array.append(np_arr)\n",
        "    y=np.array(preprocessed_array)\n",
        "    final_tensor = torch.tensor(y)\n",
        "    return final_tensor\n",
        "\n",
        "# ====================================================\n",
        "# inference\n",
        "# ====================================================\n",
        "def classifier_function(model_name, proposals, batch_size):\n",
        "  '''Classifies Each Object Proposal into one of the 15 Intellihealth Classes.\n",
        "\n",
        "  Takes the proposals, and passes each one of them through the ResNext model trained on Intellihealth Data and outputs the most confidence prediction for each proposal\n",
        "\n",
        "  Files Required:\n",
        "    The Input Configuration and The ResNext Trained Model Weights File.\n",
        "\n",
        "  Args:\n",
        "    proposals:\n",
        "      A numpy.ndarray.\n",
        "      The output of the object proposal stage.\n",
        "    batch_size:\n",
        "      An int.\n",
        "      The number of images/proposals to go thorugh in one iteration.\n",
        " \n",
        "  Returns:\n",
        "    df:\n",
        "      A pandas DataFrame.\n",
        "      Each Row Corresponds to a proposal. The columns corresponds the the 15 Intellihealth Classes.\n",
        "  '''\n",
        "\n",
        "    model = CustomResNext(CFG.model_name, pretrained=False)\n",
        "    #For CPU Inference\n",
        "    if torch.cuda.is_available()==False:\n",
        "      states = [torch.load('/content/drive/MyDrive/multilabel_retrain/models/resnext50_32x4d_fold2_best.pth', map_location=torch.device('cpu')) for fold in CFG.trn_fold]\n",
        "    else:\n",
        "      states = [torch.load('/content/drive/MyDrive/multilabel_retrain/models/resnext50_32x4d_fold2_best.pth') for fold in CFG.trn_fold]\n",
        "    # states = [torch.load('/content/drive/MyDrive/CV_multilabel_retrain/models/resnext50_32x4d_fold2_best.pth') for fold in CFG.trn_fold]\n",
        "    input_tensor = preprocess(proposals)\n",
        "    d1 = DataLoader(input_tensor, batch_size=batch_size)\n",
        "    predictions = inference(model, states, d1, device)\n",
        "    df = pd.DataFrame(predictions)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98UEW-VtAlPk"
      },
      "source": [
        "# #Sample Function Call\n",
        "# #Files Required: Model Weights File, CFG values\n",
        "# #Inputs - proposals, batch size.\n",
        "# classifier_output = classifier_function(CFG.model_name, proposals, CFG.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAA58IVk5ZN2"
      },
      "source": [
        "# Classification - Plate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWeIv_RT5ZN3"
      },
      "source": [
        "# ====================================================\n",
        "# Library\n",
        "# ====================================================\n",
        "! pip -q install albumentations==0.4.6\n",
        "! pip -q install timm\n",
        "! pip -q install kornia\n",
        "\n",
        "import kornia\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import kornia\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import sys\n",
        "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from contextlib import contextmanager\n",
        "from collections import defaultdict, Counter\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "from tqdm.auto import tqdm\n",
        "from functools import partial\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "import torchvision.models as models\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
        "from albumentations import (\n",
        "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
        "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
        "    IAAAdditiveGaussianNoise, Transpose\n",
        "    )\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from albumentations import ImageOnlyTransform\n",
        "import timm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# Get Path of all images in a folder\n",
        "# ====================================================\n",
        "def get_path(TEST_PATH):\n",
        "    image_names = os.listdir(TEST_PATH) #list of images\n",
        "    list_of_images = []\n",
        "    for f in image_names: #iterating over each image to get its name\n",
        "        image_path = os.path.join(TEST_PATH, f) #joining name with path of the parent directory to get the path of the image\n",
        "        list_of_images.append(image_path)\n",
        "    return list_of_images\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# Utils\n",
        "# ====================================================\n",
        "\n",
        "@contextmanager\n",
        "def timer(name):\n",
        "    t0 = time.time()\n",
        "    LOGGER.info(f'[{name}] start')\n",
        "    yield\n",
        "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
        "\n",
        "\n",
        "def init_logger(log_file=Plate_OUTPUT_DIR+'inference.log'):\n",
        "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
        "    logger = getLogger(__name__)\n",
        "    logger.setLevel(INFO)\n",
        "    handler1 = StreamHandler()\n",
        "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
        "    handler2 = FileHandler(filename=log_file)\n",
        "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
        "    logger.addHandler(handler1)\n",
        "    logger.addHandler(handler2)\n",
        "    return logger\n",
        "\n",
        "LOGGER = init_logger()\n",
        "\n",
        "\n",
        "def seed_torch(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_torch(seed=CFG.seed)\n",
        "\n",
        "\n",
        "if CFG.debug:\n",
        "    test = test.head()\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# MODEL\n",
        "# ====================================================\n",
        "class Plate_CustomResNext(nn.Module):\n",
        "    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
        "        n_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(n_features, Plate_CFG.target_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "# ====================================================\n",
        "# Helper functions\n",
        "# ====================================================\n",
        "def Plate_inference(model, states, test_loader, device):\n",
        "    model.to(device)\n",
        "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
        "    probs = []\n",
        "    for i, (images) in tk0:\n",
        "        images = images.to(device)\n",
        "        avg_preds = []\n",
        "        for state in states:\n",
        "            model.load_state_dict(state['model'])\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                y_preds = model(images)\n",
        "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
        "        avg_preds = np.mean(avg_preds, axis=0)\n",
        "        probs.append(avg_preds)\n",
        "    probs = np.concatenate(probs)\n",
        "    return probs\n",
        "\n",
        "def Plate_preprocess(proposals):\n",
        "    preprocessed_array = []\n",
        "    number, height, width, channels = proposals.shape\n",
        "    for i in range(number):\n",
        "        preprocess = transforms.Compose([\n",
        "                                         transforms.ToPILImage(),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Scale(256),\n",
        "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                         ])\n",
        "        j = preprocess(proposals[i])\n",
        "        np_arr = j.cpu().detach().numpy()\n",
        "        preprocessed_array.append(np_arr)\n",
        "    y=np.array(preprocessed_array)\n",
        "    final_tensor = torch.tensor(y)\n",
        "    return final_tensor\n",
        "\n",
        "# ====================================================\n",
        "# inference\n",
        "# ====================================================\n",
        "def Plate_classifier_function(model_name, proposals, batch_size):\n",
        "  '''Classifies Each Object Proposal Plate or Not Plate.\n",
        "\n",
        "  Takes the proposals, and passes each one of them through the ResNext model trained on Plate And Not Plate Data and outputs the confidence for each proposal.\n",
        "\n",
        "  Files Required:\n",
        "    The Input Configuration and The ResNext Trained Model Weights File.\n",
        "\n",
        "  Args:\n",
        "    proposals:\n",
        "      A numpy.ndarray.\n",
        "      The output of the object proposal stage.\n",
        "    batch_size:\n",
        "      An int.\n",
        "      The number of images/proposals to go thorugh in one iteration.\n",
        " \n",
        "  Returns:\n",
        "    df:\n",
        "      A pandas DataFrame.\n",
        "      Each Row Corresponds to a proposal. The column corresponds to the confidence score of the class Plate.\n",
        "  '''\n",
        "\n",
        "    model = Plate_CustomResNext(Plate_CFG.model_name, pretrained=False)\n",
        "    if torch.cuda.is_available()==False:\n",
        "      states = [torch.load(Plate_MODEL_DIR+f'{Plate_CFG.model_name}_fold{fold}_best.pth', map_location=torch.device('cpu')) for fold in Plate_CFG.trn_fold]\n",
        "    else:\n",
        "      states = [torch.load(Plate_MODEL_DIR+f'{Plate_CFG.model_name}_fold{fold}_best.pth') for fold in Plate_CFG.trn_fold]\n",
        "    # states = [torch.load('/content/drive/MyDrive/classification_plate/models/resnext50_32x4d_fold2_best.pth') for fold in Plate_CFG.trn_fold]\n",
        "    input_tensor = Plate_preprocess(proposals)\n",
        "    d1 = DataLoader(input_tensor, batch_size=batch_size)\n",
        "    predictions = Plate_inference(model, states, d1, device)\n",
        "    # df = pd.DataFrame(predictions)\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df['Plate'] = predictions.argmax(1)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmbsA37UB-Pm"
      },
      "source": [
        "# Generating Final Food labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLOGvJQ08ocb"
      },
      "source": [
        "#Function For Generating Final Boxes After Classification Stage\n",
        "import numpy as np\n",
        "import time\n",
        "from time import perf_counter\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#Inputs:\n",
        "target_cols=[\n",
        "                 \"Apple_Pie\",\"Bagel_With_Cream_Cheese\",\"Banana\",\"Blackberries\",\"Black_Grapes\",\"Chicken_Breast\",\n",
        "                 \"Chicken_Burrito_Bowl\",\"Cookie\",\"Energy_Bars\",\"French_Fries\",\"Fruit_Flavored_Yogurts\",\"Pasta\",\n",
        "                 \"Toasted_Bagel_With_Butter\",\"Toasted_Bread\",\"White_Rice\"\n",
        "                 ]\n",
        "\n",
        "classifier_output = None # The Dataframe output of the classification model\n",
        "classifier_confidence_thresh = 90\n",
        "nms_thresh = 0.1\n",
        "image_path = '/content/Rice_Img1.jpeg'\n",
        "\n",
        "#Edited nms function to output boxes as well as probabilities\n",
        "def non_max_suppression(boxes, probs=None, overlapThresh=0.3):\n",
        "    # if there are no boxes, return an empty list\n",
        "    if len(boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # if the bounding boxes are integers, convert them to floats -- this\n",
        "    # is important since we'll be doing a bunch of divisions\n",
        "    if boxes.dtype.kind == \"i\":\n",
        "        boxes = boxes.astype(\"float\")\n",
        "\n",
        "    # initialize the list of picked indexes\n",
        "    pick, probas = [], []\n",
        "\n",
        "    # grab the coordinates of the bounding boxes\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "\n",
        "    # compute the area of the bounding boxes and grab the indexes to sort\n",
        "    # (in the case that no probabilities are provided, simply sort on the\n",
        "    # bottom-left y-coordinate)\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    idxs = y2\n",
        "\n",
        "    # if probabilities are provided, sort on them instead\n",
        "    if probs is not None:\n",
        "        idxs = probs\n",
        "\n",
        "    # sort the indexes\n",
        "    idxs = np.argsort(idxs)\n",
        "\n",
        "    # keep looping while some indexes still remain in the indexes list\n",
        "    while len(idxs) > 0:\n",
        "        # grab the last index in the indexes list and add the index value\n",
        "        # to the list of picked indexes\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "\n",
        "        probas.append(probs[i])\n",
        "\n",
        "        # find the largest (x, y) coordinates for the start of the bounding\n",
        "        # box and the smallest (x, y) coordinates for the end of the bounding\n",
        "        # box\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        # compute the width and height of the bounding box\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "\n",
        "        # compute the ratio of overlap\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "\n",
        "        # delete all indexes from the index list that have overlap greater\n",
        "        # than the provided overlap threshold\n",
        "        idxs = np.delete(idxs, np.concatenate(([last],\n",
        "                                               np.where(overlap > overlapThresh)[0])))\n",
        "\n",
        "    # return only the bounding boxes that were picked\n",
        "    return boxes[pick].astype(\"int\"), probas \n",
        "\n",
        "def generate_final_boxes(classifier_output, target_cols, boxes, image_path, classifier_confidence_thresh=90, nms_thresh=0.1, image_dims = (416,416), visualize=False):\n",
        "  '''Generates the final labels, boxes and confidences given the clasifier stage input. \n",
        "\n",
        "  Files Required:\n",
        "    None.\n",
        "\n",
        "  Args:\n",
        "    classifier_output:\n",
        "      A pandas DataFrame.\n",
        "      The output of the classifier stage.\n",
        "    target_cols:\n",
        "      A list.\n",
        "      The list of classes in the order that they were presnt in the classes.txt file, to map the the model output to food labels.\n",
        "    boxes:\n",
        "      A list of shape (no. of proposals, 4).\n",
        "      Output of the object proposal stage.\n",
        "    classifier_confidence:\n",
        "      Classifier Confidence for eliminating boxes.\n",
        "    nms_threshold:\n",
        "      A float.\n",
        "    image_path:\n",
        "      A string.\n",
        "      Path of the input image for visualization.\n",
        "    image_dims:\n",
        "     Input image resized dims while sending to object proposal genrator - by default (416,416).\n",
        "    visualize:\n",
        "      Will visualize the output, if set to True.\n",
        "      (default is False)\n",
        "  \n",
        "  Returns:\n",
        "    labels:\n",
        "      A dictionary.\n",
        "      A dictionary containing - Final Boxes, Labels and Confidences.\n",
        "  '''\n",
        "\n",
        "  if visualize:\n",
        "    width, height = image_dims\n",
        "\n",
        "  #Data Frame Input\n",
        "  preds = classifier_output.to_numpy()\n",
        "\n",
        "  #Convert Preds Probability To 0-100 range\n",
        "  for i in range(preds.shape[0]):\n",
        "    preds[i] = preds[i]*100\n",
        "\n",
        "  #Select Highest Confident Class Index For Each Image\n",
        "  max_preds = np.argmax(preds, axis=1)\n",
        "\n",
        "  #List With Class And Confidence of Each Box\n",
        "  preds2 = []\n",
        "  for i in range(preds.shape[0]):\n",
        "    preds2.append([(target_cols[max_preds[i]] , preds[i][max_preds[i]])])\n",
        "\n",
        "\n",
        "  #Confidence Based Elimination\n",
        "  labels = {}\n",
        "  preds = preds2 \n",
        "\n",
        "  print(preds)\n",
        "  for (i, p) in enumerate(preds):\n",
        "    (label, prob) = p[0] \n",
        "    if prob >= classifier_confidence_thresh:\n",
        "      (x, y, w, h) = boxes[i]\n",
        "      box = (x, y, x + w, y + h)\n",
        "      L = labels.get(label, [])\n",
        "      L.append((box, prob))\n",
        "      labels[label] = L\n",
        "\n",
        "  count = 0\n",
        "  for i in labels.values():\n",
        "    count += np.shape(i)[0]\n",
        "\n",
        "  print('Number of boxes after confidence based elimination =  {:.4f}'.format(count))\n",
        "\n",
        "  #nms based elimination\n",
        "\n",
        "  t1_start = perf_counter()\n",
        "\n",
        "  count = 0 \n",
        "\n",
        "  for label in labels.keys():\n",
        "\n",
        "    boxess = np.array([p[0] for p in labels[label]])\n",
        "    proba = np.array([p[1] for p in labels[label]])\n",
        "    # print('!!!', non_max_suppression(boxess, proba, nms_thresh)) #CV DB\n",
        "    boxess, probas = non_max_suppression(boxess, proba, nms_thresh)\n",
        "    count += boxess.shape[0]\n",
        "\n",
        "    final_boxes_and_probs = [(b, p) for b,p in zip(boxess,probas)]\n",
        "    labels[label] = final_boxes_and_probs\n",
        "\n",
        "    if visualize:\n",
        "      print(\"[INFO] showing results for '{}'\".format(label))\n",
        "      # for (startX, startY, endX, endY) in boxess:\n",
        "\n",
        "      clone = cv2.imread(image_path)\n",
        "      (H,W) = clone.shape[:2]\n",
        "      if W>H:\n",
        "        clone = imutils.resize(clone, width=width)\n",
        "      else: \n",
        "        clone = imutils.resize(clone, height=height)\n",
        "\n",
        "\n",
        "      for (startX, startY, endX, endY), p in zip(boxess,probas):\n",
        "      \n",
        "        #Viz Code\n",
        "        # clone = cv2.imread(image_path)\n",
        "        # (H,W) = clone.shape[:2]\n",
        "        # if W>H:\n",
        "        #   clone = imutils.resize(clone, width=width)\n",
        "        # else: \n",
        "        #   clone = imutils.resize(clone, height=height)\n",
        "\n",
        "      #   # draw the bounding box and label on the image\n",
        "      #   cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
        "      #     (0, 255, 0), 2)\n",
        "      #   y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "      #   cv2.putText(clone, label, (startX, y),\n",
        "      #     cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
        "      # # show the output after apply non-maxima suppression\n",
        "      # cv2_imshow(clone)\n",
        "      # cv2.waitKey(0)\n",
        "        cv2.rectangle(clone, (startX, startY), (endX, endY),\n",
        "          (0, 255, 0), 2)\n",
        "        y = startY + 15\n",
        "        cv2.putText(clone, label + ' :  ' + str(round(p,2)), (startX, y),\n",
        "          cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
        "      cv2_imshow(clone)\n",
        "      cv2.waitKey(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  t1_stop = perf_counter()\n",
        "\n",
        "  print('Time for applying NMS =  {:.4f} seconds'.format(t1_stop-t1_start))\n",
        "  print('Number Of Boxes after NMS = ', count)\n",
        "\n",
        "  \n",
        "  return labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21pUhv8dsdDD"
      },
      "source": [
        "#Object Detection - Plate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoWjbTGstIhy",
        "outputId": "d0673657-8d66-4c15-fd5f-a86313029ae1"
      },
      "source": [
        "!pip install opencv-contrib-python==4.5.1.48"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-contrib-python==4.5.1.48 in /usr/local/lib/python3.7/dist-packages (4.5.1.48)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==4.5.1.48) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p_a283TshC1"
      },
      "source": [
        "#Function Imports\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import imutils\n",
        "\n",
        "\n",
        "#Load The Model\n",
        "weightsPath = \"/content/drive/MyDrive/PlateDetector/YOLO/Weights-T1/yolov4-obj_best.weights\"\n",
        "configPath = \"/content/drive/MyDrive/PlateDetector/YOLO/yolov4-obj.cfg\"\n",
        "\n",
        "def load_model(configPath=configPath, weightsPath=weightsPath):\n",
        "  net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
        "  model = cv2.dnn_DetectionModel(net)\n",
        "  model.setInputParams(size=(416, 416), scale=1/255, swapRB=True)\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "image_path =  \"/content/Rice_Img1.jpeg\"\n",
        "config_thresh = 0.75\n",
        "nms_thresh = 0.3\n",
        "\n",
        "\n",
        "def generate_predictions(model, image_path=image_path, config_thresh=config_thresh, nms_thresh=nms_thresh, visualize=True):\n",
        "  '''Detects Plate Boxes for a given image.\n",
        "\n",
        "  Files Required:\n",
        "    YOLOv4 darknet weights and cfg file.\n",
        "\n",
        "  Args:\n",
        "    model:\n",
        "      The model created using the openCV's dnn module in the load_model function above.\n",
        "    image_path:\n",
        "      A string.\n",
        "    config_thresh:\n",
        "      A float.\n",
        "      The confidence threshold to filter the final output.\n",
        "      (default is 0.75)\n",
        "    nms_thresh:\n",
        "      A float.\n",
        "      (default is 0.3)\n",
        "    visualize:\n",
        "      Will visualize the output, if set to True.\n",
        "      (default is False)\n",
        "\n",
        "  Returns:\n",
        "    classes, confidence scores and the boxes for the predictions generated.\n",
        "  '''\n",
        "\n",
        "  image = cv2.imread(image_path)\n",
        "  #resize image #Default 416,416\n",
        "  (H,W) = image.shape[:2]\n",
        "\n",
        "  width, height = (416,416) #CV !!!\n",
        "  if W>H:\n",
        "    image = imutils.resize(image, width=width)\n",
        "  else: \n",
        "    image = imutils.resize(image, height=height)\n",
        "\n",
        "  t1 = time.perf_counter()\n",
        "  classes, scores, boxes = model.detect(image, config_thresh, nms_thresh)\n",
        "  t2 = time.perf_counter()\n",
        "  print('The Model Took', t2-t1, 'seconds')\n",
        "  if visualize:\n",
        "    if np.shape(boxes)[0]!=0:\n",
        "      print('Visualizing..')\n",
        "      class_names=['Plate']\n",
        "      for (classid, score, box) in zip(classes, scores, boxes):\n",
        "          label = \"%s : %f\" % (class_names[classid[0]], score)\n",
        "          # color = (0,0,255)\n",
        "          color = (255,0,0)\n",
        "          cv2.rectangle(image, box, color, 10)\n",
        "          # box = [396,   38, 4128, 3096 ]   #CV D\n",
        "          # box = [0,   0, 3169, 2933] #CV D\n",
        "          # cv2.rectangle(image, box, color, 10) #CV D\n",
        "          # cv2.putText(image, label, (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "          cv2.putText(image, label, (box[0], box[1] + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 10)\n",
        "          # cv2_imshow(image)\n",
        "      image = cv2.resize(image, (416, 416))   \n",
        "      cv2_imshow(image)\n",
        "      print('\\n')\n",
        "      print('\\n')\n",
        "\n",
        "    else:\n",
        "      print('No Boxes Detected')\n",
        "      image = cv2.resize(image, (416, 416))   \n",
        "      cv2_imshow(image)\n",
        "      print('\\n')\n",
        "      print('\\n')\n",
        "\n",
        "\n",
        "  return classes, scores, boxes\n",
        "\n",
        "\n",
        "\n",
        "#Calling Functions\n",
        "# plate_model = load_model(configPath, weightsPath)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjTCxdSNsXAe"
      },
      "source": [
        "plate_model = load_model(configPath,weightsPath)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEP-9jIirdyJ"
      },
      "source": [
        "#Postprocessing Using Food Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kO4GyBWriFD"
      },
      "source": [
        "#Postprocessing\n",
        "#Function\n",
        "\n",
        "def generate_final_result(labels, food_dic, plate_scores, plate_boxes):\n",
        "  ''' Generates the final food labels, servings and calories\n",
        "\n",
        "  Files Required:\n",
        "    None \n",
        "    \n",
        "  Args:\n",
        "    labels:\n",
        "      A dictionary.\n",
        "      The output of the generating final food labels stage.\n",
        "    food_dic:\n",
        "      A dictionary.\n",
        "      The Dicitionary used to calculate final serving and calories.\n",
        "    plate_scores and plate_boxes:\n",
        "      The scores and boxes output of the plate detection stage.\n",
        "\n",
        "  Returns:\n",
        "    final_output:\n",
        "      A dictionary.\n",
        "      Dictionary contains the final food labels, servings, serving size and calories.\n",
        "  '''\n",
        "\n",
        "  final_output = {}\n",
        "  try:\n",
        "    index = np.argmax(plate_scores)\n",
        "    #If multiple plates of highest confidence pick 1\n",
        "    if  type(index) == np.ndarray:\n",
        "      index = index[0]\n",
        "    box = plate_boxes[index]\n",
        "    # print(box,type(box), box[2],box[0],box[1],box[3])\n",
        "    plate_area = (box[2]-box[0])*(box[3]-box[1])\n",
        "  \n",
        "  except ValueError:\n",
        "    plate_area = 0\n",
        "\n",
        "  # print(plate_area)\n",
        "  for label in labels:\n",
        "    # print('!!! 1',label)\n",
        "    final_output[label] = {}\n",
        "    if food_dic[label]['calorie_measure'] == 'count':\n",
        "      final_output[label]['serving size'] = '1'\n",
        "      final_output[label]['servings'] = len(labels[label])\n",
        "      final_output[label]['calories'] = final_output[label]['servings'] * food_dic[label]['calories_kcal']\n",
        "\n",
        "    elif food_dic[label]['calorie_measure'] == 'area':\n",
        "      # print('!!! 2',label)\n",
        "\n",
        "  #Approach 1 (Based On Per Plate)\n",
        "\n",
        "      #For all the boxes\n",
        "      food_area = 0\n",
        "      for box_conf in labels[label]:\n",
        "        box = box_conf[0]\n",
        "        food_area += (box[2]-box[0])*(box[3]-box[1])\n",
        "\n",
        "      # print('!!!',food_area, plate_area)\n",
        "      # print(final_output)\n",
        "      final_output[label]['serving size'] = str(1) + ' plate(s)'\n",
        "      if plate_area == 0:\n",
        "        # print('!!! 3', label)\n",
        "        final_output[label]['servings'] = '-'\n",
        "        final_output[label]['calories'] = '-'\n",
        "      else:  \n",
        "        final_output[label]['servings'] = food_area/plate_area\n",
        "        final_output[label]['calories'] = str(final_output[label]['servings'] * food_dic[label][\"calories_kcal\"]) + ' kcal'\n",
        "    \n",
        "      # print('!!! 4',final_output)\n",
        "\n",
        "  # print('Food Item','          ', 'Servings','          ', '*','          ', 'Serving Size','          ', 'Calories')\n",
        "  # for l in final_output:\n",
        "    # print(l, final_output[l]['servings'],'          ', '*','          ', final_output[l]['serving size'],'          ', final_output[l]['calories'])\n",
        "\n",
        "  items = len(list(final_output.keys()))\n",
        "  fod = pd.DataFrame()\n",
        "  fod['Food Item'] = ['-' for i in range(items)]\n",
        "  fod['Servings'] = ['-' for i in range(items)]\n",
        "  fod['Serving Size'] = ['-' for i in range(items)]\n",
        "  fod['Calories'] = ['-' for i in range(items)]\n",
        "  # print('!!!',final_output)\n",
        "  for i,label in enumerate(final_output):\n",
        "    # print('!!!', label)\n",
        "    fod['Food Item'][i] = label\n",
        "    fod['Servings'][i] = final_output[label]['servings']\n",
        "    fod['Serving Size'][i] = final_output[label]['serving size']\n",
        "    fod['Calories'][i] = final_output[label]['calories']\n",
        "    # print(l, final_output[l]['servings'],'          ', '*','          ', final_output[l]['serving size'],'          ', final_output[l]['calories'])\n",
        "  print(fod)\n",
        "  print('')\n",
        "\n",
        "  return final_output\n",
        "\n",
        "# #Approach 2 (Based On Per Gram)\n",
        "#     food_area = 0\n",
        "#     for box_conf in labels2[label]:\n",
        "#       box = box_conf[0]\n",
        "#       food_area += (box[2]-box[0])*(box[1]-box[3])\n",
        "\n",
        "#     food_volume = food_area*2 #cm2 \n",
        "#     food_mass  = food_volume * food_dic[label]['density']\n",
        "\n",
        "#     final_output[label]['serving size'] = food_dic[label]['serving_size']\n",
        "#     final_output[label]['servings'] = food_mass/food_dic[label]['serving_size']\n",
        "#     final_output[label]['calories'] = final_output[label]['servings'] * food_dic[label]['Calories_Per_Plate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZLd8DnMRnmc"
      },
      "source": [
        "# Main()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYgYQ9hUjMCG"
      },
      "source": [
        "#Final End-To-End Function.\n",
        "\n",
        "max_boxes = 10\n",
        "classifier_confidence_thresh = 90\n",
        "Plate_classifier_confidence_thresh = 80\n",
        "\n",
        "def predict_calories(image_path, obj_proposals = 'EB', plate_detection = 'OD'):\n",
        "  '''Predicts Food Labels, Servings and Calories given an input image.\n",
        "\n",
        "  Args:\n",
        "    image_path:\n",
        "      A string.\n",
        "      Absolute path to the image.\n",
        "    obj_proposals:\n",
        "      A string.\n",
        "      The method to use for generating object proposals. Edge Boxes - \"EB\" or Selective Search - \"SS\".\n",
        "      (default is \"EB\")\n",
        "    plate_detection:\n",
        "      A string.\n",
        "      Method to use for plate_detection. Image Classification - \"IC\" or Object Detection - \"OD\".\n",
        "      (default is \"OD\")      \n",
        " \n",
        "  Returns:\n",
        "    final_output:\n",
        "      A dictionary. Contains the final food labels, servings and calories.\n",
        "  '''\n",
        "\n",
        "\n",
        "  top1 = perf_counter()\n",
        "  if obj_proposals == 'SS':\n",
        "    # Generate Object Proposals - SS\n",
        "    proposals, boxes = selective_search_cv(image_path, method, percentage, image_dims=(416,416), proposal_dims = (224,224))\n",
        "  elif obj_proposals == 'EB':\n",
        "    # # Generate proposals - EB\n",
        "    proposals, boxes = get_proposals(image_path, image_dims, proposal_dims, max_boxes, percentage, eb_model_path)\n",
        "\n",
        "\n",
        "  top2 = perf_counter()\n",
        "  top = top2-top1\n",
        "\n",
        "\n",
        "  tfc1 = perf_counter()\n",
        "\n",
        "  #No proposals case  \n",
        "  if len(proposals) == 0:\n",
        "    # print('******************************************************************')\n",
        "    classifier_output= edf\n",
        "\n",
        "  else:\n",
        "    #Classify Proposals - Food\n",
        "    classifier_output = classifier_function(CFG.model_name, proposals, CFG.batch_size)\n",
        "    #Generate Final Food Labels\n",
        "  labels = generate_final_boxes(classifier_output, target_cols, boxes, image_path, classifier_confidence_thresh, nms_thresh, image_dims = (416,416), visualize=True)\n",
        "  tfc2 = perf_counter()\n",
        "  tfc = tfc2-tfc1\n",
        "\n",
        "\n",
        "  tpd1 = perf_counter()\n",
        "  if plate_detection =='IC':\n",
        "    if len(proposals) == 0:\n",
        "      # print('******************************************************************')\n",
        "      Plate_classifier_output = pd.DataFrame()\n",
        "      Plate_classifier_output['Plate']= [0]\n",
        "    else:\n",
        "      #Classify Proposals - Plate\n",
        "      Plate_classifier_output = Plate_classifier_function(Plate_CFG.model_name, proposals, Plate_CFG.batch_size)\n",
        "      # print(Plate_classifier_output)\n",
        "\n",
        "\n",
        "    #Generate Final Plate Labels\n",
        "    Plate_labels = generate_final_boxes(Plate_classifier_output, Plate_target_cols, boxes, image_path, Plate_classifier_confidence_thresh, Plate_nms_thresh, image_dims = (416,416), visualize=True)\n",
        "    # print(Plate_labels)\n",
        "    ##Generate Plate Boxes\n",
        "    boxes = []\n",
        "    scores = []\n",
        "    if len(list(Plate_labels.keys())) != 0 :\n",
        "      for pair in Plate_labels['Plate']:\n",
        "        boxes.append(pair[0])\n",
        "        scores.append(pair[1])\n",
        "    # print(boxes)\n",
        "    # print(scores)\n",
        "    # print(np.argmax(scores))\n",
        "\n",
        "  elif plate_detection == 'OD':\n",
        "    # Generate Plate Boxes - YOLO\n",
        "    # #Load Model\n",
        "    # plate_model = load_model(configPath,weightsPath)\n",
        "    ##Detect Plates\n",
        "    classes, scores, boxes = generate_predictions(plate_model, image_path)\n",
        "    print(boxes)\n",
        "    print(scores)\n",
        "\n",
        "  tpd2 = perf_counter()\n",
        "  tpd = tpd2-tpd1\n",
        "\n",
        "  tp1 = perf_counter()\n",
        "  #Posprocessing Using Food Dictionary  \n",
        "  final_output = generate_final_result(labels, food_dic, scores, boxes)\n",
        "  tp2 = perf_counter()\n",
        "  tp = tp2-tp1\n",
        "\n",
        "  tdf = pd.DataFrame()\n",
        "  tdf['Stage'] = ['Object Proposal', 'Food Classification', 'Plate Detection', 'Post-processing With Food Dictionary']\n",
        "  tdf['Method'] = [obj_proposals, 'Multi Label Image Classifier', plate_detection, '-' ]\n",
        "  tdf['Time'] = [top, tfc, tpd,tp]\n",
        "\n",
        "  print(tdf)\n",
        "  print('')\n",
        "  print('Total Time Taken:' , top+tfc+tpd+tp,'s')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXVQswz7Aorw",
        "outputId": "0c5702f4-5c52-4754-cc3c-9827ef54f070"
      },
      "source": [
        "    image_path = '/content/drive/MyDrive/PlateDetector/YOLO/Plate_Detector_Ih_GroundTruth/Banana_Img3.jpeg'\n",
        "percentage = 0.05\n",
        "predict_calories(image_path, 'SS', 'IC')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] selective search took 1.4656 seconds\n",
            "[INFO] 196 regions found by selective search\n",
            "[INFO] Proposals Shape After Size Based Elimination: (0,)\n",
            "[INFO] Boxes Shape After Size Based Elimination: (0,)\n",
            "[[('Apple_Pie', 0)]]\n",
            "Number of boxes after confidence based elimination =  0.0000\n",
            "Time for applying NMS =  0.0000 seconds\n",
            "Number Of Boxes after NMS =  0\n",
            "[[('Plate', 0)]]\n",
            "Number of boxes after confidence based elimination =  0.0000\n",
            "Time for applying NMS =  0.0000 seconds\n",
            "Number Of Boxes after NMS =  0\n",
            "Empty DataFrame\n",
            "Columns: [Food Item, Servings, Serving Size, Calories]\n",
            "Index: []\n",
            "\n",
            "                                  Stage                        Method      Time\n",
            "0                       Object Proposal                            SS  2.770270\n",
            "1                   Food Classification  Multi Label Image Classifier  0.001626\n",
            "2                       Plate Detection                            IC  0.005546\n",
            "3  Post-processing With Food Dictionary                             -  0.003624\n",
            "\n",
            "Total Time Taken: 2.781065398999999 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2k8q9J442v_"
      },
      "source": [
        "list_of_images = get_path(TEST_PATH)\n",
        "percentage = 0.1\n",
        "for image_path in list_of_images:\n",
        "  # proposals, boxes = selective_search_cv(image_path, method,percentage, image_dims=(416,416), proposal_dims = (224,224))\n",
        "  # classifier_output = classifier_function(CFG.model_name, proposals, CFG.batch_size)\n",
        "  # generate_final_boxes(classifier_output, target_cols, boxes, image_path, classifier_confidence_thresh=90, nms_thresh=0.1, image_dims = (416,416), visualize=True)\n",
        "  predict_calories(image_path, 'SS', 'IC')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW_ewAWlVaif"
      },
      "source": [
        "# #Single Image\n",
        "# image_path = '/content/Rice_Img1.jpeg'\n",
        "\n",
        "# # Generate Object Proposals - SS\n",
        "# proposals, boxes = selective_search_cv(image_path, method,percentage, image_dims=(416,416), proposal_dims = (224,224))\n",
        "\n",
        "\n",
        "# # # Generate proposals - EB\n",
        "# # img, proposals, boxes = get_proposals(image_path, (416, 416), (224, 224), 100)\n",
        "# proposals, boxes = get_proposals(image_path, image_dims, proposal_dims, max_boxes, percentage, eb_model_path)\n",
        "\n",
        "\n",
        "# #Classify Proposals - Food\n",
        "# classifier_output = classifier_function(CFG.model_name, proposals, CFG.batch_size)\n",
        "# #Generate Final Food Labels\n",
        "# labels = generate_final_boxes(classifier_output, target_cols, boxes, image_path, classifier_confidence_thresh=90, nms_thresh=0.1, image_dims = (416,416), visualize=True)\n",
        "\n",
        "\n",
        "# #Classify Proposals - Plate\n",
        "# Plate_classifier_output = Plate_classifier_function(Plate_CFG.model_name, proposals, Plate_CFG.batch_size)\n",
        "# # print(Plate_classifier_output)\n",
        "# #Generate Final Plate Labels\n",
        "# Plate_labels = generate_final_boxes(Plate_classifier_output, Plate_target_cols, boxes, image_path, classifier_confidence_thresh=99, nms_thresh=0.1, image_dims = (416,416), visualize=True)\n",
        "# # print(Plate_labels)\n",
        "# ##Generate Plate Boxes\n",
        "# boxes = []\n",
        "# scores = []\n",
        "# for pair in Plate_labels['Plate']:\n",
        "#   boxes.append(pair[0])\n",
        "#   scores.append(pair[1])\n",
        "# print(boxes)\n",
        "# print(scores)\n",
        "# print(np.argmax(scores))\n",
        "\n",
        "# # Generate Plate Boxes - YOLO\n",
        "# # #Load Model\n",
        "# # plate_model = load_model(configPath,weightsPath)\n",
        "# # #Detect Plates\n",
        "# # classes, scores, boxes = generate_predictions(plate_model, image_path)\n",
        "\n",
        "# #Posprocessing Using Food Dictionaryw\n",
        "# generate_final_result(labels, food_dic, scores, boxes)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}